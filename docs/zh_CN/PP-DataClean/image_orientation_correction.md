# 图像方向矫正

------


## 目录


- [1. 背景](#1)
- [2. 模型](#2)
    - [2.1 训练](#2.1)
    - [2.2 部署](#2.2)
- [3. 视觉任务表现](#3)
    - [3.1 图像分类](#3.1)
    - [3.2 目标检测](#3.2)
    - [3.3 OCR端到端识别](#3.3)

<a name="1"></a>
## 1. 背景

深度学习在计算机视觉领域已经取得了较大的发展，在视觉场景的诸多任务上已有广泛应用，我们针对模型部署中面临的数据质量问题，提出了 PP-DataClean 解决方案。

深度学习为数据驱动，模型效果极大地依赖于训练数据，而通常情况下训练数据集是针对特定问题进行设计的，这样训练得到的模型通常针对预设问题具有较好效果，但是在真实的部署场景中往往存在大量的低质量数据，这些数据极大地影响了模型的预测效果，比如图像方向问题。目前大部分视觉任务数据集均预设图像方向为正，这一点在大多真实场景中无法确保，因此其他方向的数据在预测时往往得不到预期效果，如果强行将图像方向考虑到训练数据集设计中，则又会对模型预测效果带来负面影响，或是需要更大体量的模型影响推理速度，针对上述问题，PP-DataClean 提供了图像方向矫正模型，该模型能够对图像方向进行分类预测，同时该模型极为轻量，对系统推理速度影响较小。图像方向矫正模型的使用示例如下图所示：

<div align="center">
  <img src="https://user-images.githubusercontent.com/45199522/200730301-9c6b772a-6aed-40b6-a67b-c573c91d856b.png" width = "800"/>
</div>

<a name="2"></a>
## 2. 模型介绍

在本小节我们会介绍图像方向矫正模型从训练到部署的全部流程。

<a name="2.1"></a>
#### 2.1 训练

图像方向矫正模型本质为图像分类任务，同时考虑到模型需要足够轻量，因此我们采用了 PaddleClas 的 PULC 方案，训练详情可以参考[PULC图像方向分类](https://github.com/PaddlePaddle/PaddleClas/blob/develop/docs/zh_CN/models/PULC/PULC_image_orientation.md)。

<a name="2.2"></a>
#### 2.2 部署

对于图像方向矫正模型的使用方法，我们提供了 EasyData whl 的方式，支持命令行直接预测以及在 Python 脚本中调用的方式，具体可以参考[图像方向矫正模型部署](quick_start.md#211)。

<a name="3"></a>
## 3. 视觉任务表现

图像方向矫正模型对下游任务改善显著，我们在图像分类、目标检测、OCR等任务上进行了评估，具体指标如下：

<a name="3.1"></a>
### 3.1 图像分类

对于图像分类任务，我们基于 ImageNet1k 数据集进行了评测，模型使用 [PP-LCNet_x1_0](https://github.com/PaddlePaddle/PaddleClas/blob/release/2.5/docs/zh_CN/models/ImageNet1k/PP-LCNet.md)，具体效果如下表所示：

| 是否进行方向矫正 | 原始数据评测指标 | 多方向数据评测指标 | 
| :--            | :--:   | :--:    |
| ✘              | 71.31% | 53.91%  |
| ✔（阈值0）     | 50.89% | 70.22%  |
| ✔（阈值0.80）  | 71.26% | 68.39%  |
| ✔（阈值0.90）  | 71.31% | 66.16%  |
| ✔（阈值0.95）  | 71.31% | 53.96%  |

在上表中：
* 其中指标为 Top-1 Acc；
* 原始数据为 ImageNet1k 数据集，多方向数据为基于 ImageNet1k 数据进行方向扩充后的数据集，扩充方法为：对原始图像数据分别逆时针旋转0°、90°、180°、270°得到；
* ✘ 表示不使用方向矫正模型，✔ 表示使用方向矫正模型并取不同的阈值；

<a name="3.2"></a>
### 3.2 目标检测

对于目标检测任务，我们基于 COCO 数据集进行了评测，模型使用 PPYOLOE+L，具体效果如下表所示：

| 是否进行方向矫正 | 原始数据评测指标 | 多方向数据评测指标 | 
| :--            | :--:     | :--:    |
| ✘              | 52.9%    | 31.0%   |
| ✔（阈值0）     | 52.4%    | 52.1%   |
| ✔（阈值0.80）  | 52.8%    | 51.2%   |
| ✔（阈值0.90）  | 52.9%    | 49.6%   |
| ✔（阈值0.95）  | 52.9%    | 31.1%   |

在上表中：
* 其中指标为 AP<sup>0.5:0.95；
* 原始数据为 COCO 数据集，多方向数据为基于 COCO 数据进行方向扩充后的数据集，扩充方法为：对原始图像数据分别逆时针旋转 0°、90°、180°、270°，同时修改对应的标签值；
* ✘ 表示不使用方向矫正模型，✔ 表示使用方向矫正模型并取不同的阈值；

<a name="3.3"></a>
### 3.3 OCR 端到端识别

对于 OCR 任务，我们基于 PP-OCRv2 端到端文字检测识别系统进行了实验，具体效果如下表所示：

| 是否进行方向矫正 | 原始数据评测指标 | 多方向数据评测指标 | 
| :--            | :--:      | :--:     |
| ✘              | 57.02%    | 27.21%   |
| ✔（阈值0）     | 53.78%    | 52.25%   |
| ✔（阈值0.80）  | 56.59%    | 48.78%   |
| ✔（阈值0.90）  | 57.02%    | 37.65%   |
| ✔（阈值0.95）  | 57.02%    | 27.47%   |

在上表中：
* 其中指标为 H-mean；
* 原始数据为 PP-OCRv2 端到端评测数据集，多方向数据为基于原始数据集进行方向扩充后的数据集，扩充方法为：对原始图像数据分别逆时针旋转0°、90°、180°、270°，同时修改对应的标签值；
* ✘ 表示不使用方向矫正模型，✔ 表示使用方向矫正模型并取不同的阈值；
